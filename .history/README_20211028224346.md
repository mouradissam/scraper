## Description
scraper is a distributed and versatile data crawler.

## Basic Usage
A feed requires the following three component to run properly
1. listener: It could be a messaging bus such as rabbitmq or kafka 
2. worker: subscribes to a listener and downloads the page content and stores it into a backend.
3. backend: a redis or nosql backend to store the final data

Create a FeedHandler object and add subscriptions. For the various data channels that an exchange supports, you can supply callbacks for data events, or use provided backends (described below) to handle the data for you. Start the feed handler and you're done!

```python
from cryptofeed import FeedHandler
# not all imports shown for clarity

fh = FeedHandler()

# ticker, trade, and book are user defined functions that
# will be called when ticker, trade and book updates are received
ticker_cb = {TICKER: ticker}
trade_cb = {TRADES: trade}
gemini_cb = {TRADES: trade, L2_BOOK: book}

